23-07-06 14:35:06.422 - INFO: train_data_path: ./data/mvtec
23-07-06 14:35:06.422 - INFO: save_path: ./exps/visa/vit_large_14_518
23-07-06 14:35:06.422 - INFO: config_path: ./open_clip/model_configs/ViT-L-14-336.json
23-07-06 14:35:06.422 - INFO: dataset: mvtec
23-07-06 14:35:06.422 - INFO: model: ViT-L-14-336
23-07-06 14:35:06.422 - INFO: pretrained: openai
23-07-06 14:35:06.422 - INFO: features_list: [6, 12, 18, 24]
23-07-06 14:35:06.422 - INFO: epoch: 3
23-07-06 14:35:06.422 - INFO: learning_rate: 0.001
23-07-06 14:35:06.422 - INFO: batch_size: 4
23-07-06 14:35:06.422 - INFO: image_size: 518
23-07-06 14:35:06.422 - INFO: aug_rate: 0.2
23-07-06 14:35:06.422 - INFO: print_freq: 1
23-07-06 14:35:06.422 - INFO: save_freq: 1
23-07-06 14:35:07.661 - INFO: iter 1 	 loss 4.7511773109436035
23-07-06 14:35:08.379 - INFO: iter 2 	 loss 4.090112209320068
23-07-06 14:35:08.959 - INFO: iter 3 	 loss 3.9800353050231934
23-07-06 14:35:09.610 - INFO: iter 4 	 loss 4.1430206298828125
23-07-06 14:35:10.205 - INFO: iter 5 	 loss 3.8948588371276855
23-07-06 14:35:10.793 - INFO: iter 6 	 loss 3.627626419067383
23-07-06 14:35:11.358 - INFO: iter 7 	 loss 3.971292495727539
23-07-06 14:35:11.977 - INFO: iter 8 	 loss 3.7876596450805664
23-07-06 14:35:12.569 - INFO: iter 9 	 loss 3.5872201919555664
23-07-06 14:35:13.364 - INFO: iter 10 	 loss 3.8883092403411865
23-07-06 14:35:14.129 - INFO: iter 11 	 loss 3.0032525062561035
23-07-06 14:35:14.800 - INFO: iter 12 	 loss 2.9119482040405273
23-07-06 14:35:15.581 - INFO: iter 13 	 loss 3.1601760387420654
23-07-06 14:35:16.211 - INFO: iter 14 	 loss 2.4451160430908203
23-07-06 14:35:16.836 - INFO: iter 15 	 loss 6.046175956726074
23-07-06 14:35:17.679 - INFO: iter 16 	 loss 3.0330381393432617
23-07-06 14:35:18.246 - INFO: iter 17 	 loss 3.121392250061035
23-07-06 14:35:18.816 - INFO: iter 18 	 loss 3.238344192504883
23-07-06 14:35:19.492 - INFO: iter 19 	 loss 3.017740249633789
23-07-06 14:35:20.203 - INFO: iter 20 	 loss 2.452775001525879
23-07-06 14:35:20.951 - INFO: iter 21 	 loss 3.351278781890869
23-07-06 14:35:21.559 - INFO: iter 22 	 loss 3.2116918563842773
23-07-06 14:35:22.325 - INFO: iter 23 	 loss 3.914923906326294
23-07-06 14:35:23.040 - INFO: iter 24 	 loss 3.666506767272949
23-07-06 14:35:23.692 - INFO: iter 25 	 loss 2.8021042346954346
23-07-06 14:35:24.427 - INFO: iter 26 	 loss 3.3833985328674316
23-07-06 14:35:25.097 - INFO: iter 27 	 loss 3.61171817779541
23-07-06 14:35:25.879 - INFO: iter 28 	 loss 3.3393301963806152
23-07-06 14:35:26.843 - INFO: iter 29 	 loss 3.587576389312744
23-07-06 14:35:27.465 - INFO: iter 30 	 loss 3.503462791442871
23-07-06 14:35:28.082 - INFO: iter 31 	 loss 3.715942859649658
23-07-06 14:35:28.721 - INFO: iter 32 	 loss 2.186838388442993
23-07-06 14:35:29.460 - INFO: iter 33 	 loss 3.306297779083252
23-07-06 14:35:30.241 - INFO: iter 34 	 loss 2.7354960441589355
23-07-06 14:35:31.007 - INFO: iter 35 	 loss 2.3944857120513916
23-07-06 14:35:31.797 - INFO: iter 36 	 loss 4.29578971862793
23-07-06 14:35:32.639 - INFO: iter 37 	 loss 3.131309986114502
23-07-06 14:35:33.274 - INFO: iter 38 	 loss 2.827878952026367
23-07-06 14:35:34.051 - INFO: iter 39 	 loss 3.152841806411743
